{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "958efaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from IPython.display import display, Markdown\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55a96a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66b4a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()  # Uses your OPENAI_API_KEY from environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9ca2716",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\n",
    "            \"role\": \"system\",\n",
    "            \"content\": 'You are a stand-up comic performing to an audience of data    scientists. Your specialist genre is dad jokes.'\n",
    "        }, {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": 'Tell a joke about statistics.'\n",
    "        }, {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": 'My last was gig at a statistics conference. I told 100 jokes to try       and make people laugh. No pun in ten did.'\n",
    "        }\n",
    "     ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9236e401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the statistician break up with the baseball player? She       caught him rounding the bases with another woman.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b7792b",
   "metadata": {},
   "source": [
    "#### Control randomness with temperature (default is 1)\n",
    "#### temperature=0 gives highly deterministic output\n",
    "#### temperature=2 gives highly random output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bd2cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\n",
    "            \"role\": \"system\",\n",
    "            \"content\": 'You are a stand-up comic performing to an audience of data    scientists. Your specialist genre is dad jokes.'\n",
    "        }, {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": 'Tell a joke about statistics.'\n",
    "        }, {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": 'My last was gig at a statistics conference. I told 100 jokes to try       and make people laugh. No pun in ten did.'\n",
    "        }\n",
    "     ], \n",
    "     temperature=0.5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce303416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the statistician break up with the baseball player? She       caught him rounding the bases with another woman.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a120b54d",
   "metadata": {},
   "source": [
    "#### Control randomness using nucleus sampling with top_p (default is 1)\n",
    "#### top_p = 0 gives highly deterministic output\n",
    "#### top_p = 1 gives highly random output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0b53fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\n",
    "            \"role\": \"system\",\n",
    "            \"content\": 'You are a stand-up comic performing to an audience of data    scientists. Your specialist genre is dad jokes.'\n",
    "        }, {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": 'Tell a joke about statistics.'\n",
    "        }, {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": 'My last was gig at a statistics conference. I told 100 jokes to try       and make people laugh. No pun in ten did.'\n",
    "        }\n",
    "     ], \n",
    "    top_p=0.5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72c366bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why did the statistician break up with the mathematician? He couldn't handle her irrational behavior!\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69720a21",
   "metadata": {},
   "source": [
    "#### Control talking about new topics using presence_penalty (default is 0)\n",
    "#### presence_penalty=-2 gives more repetition in conversations\n",
    "#### presence_penalty=2 gives more novelty in conversations\n",
    "#### frequency_penalty behaves similarly, but counts number of instances of previous tokens rather than detecting their presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5614f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why do data scientists always carry around a ruler?\\n\\nIn case they need to draw a normal distribution!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\n",
    "            \"role\": \"system\",\n",
    "            \"content\": 'You are a stand-up comic performing to an audience of data    scientists. Your specialist genre is dad jokes.'\n",
    "        }, {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": 'Tell a joke about statistics.'\n",
    "        }, {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": 'My last was gig at a statistics conference. I told 100 jokes to try       and make people laugh. No pun in ten did.'\n",
    "        }\n",
    "     ], \n",
    "     presence_penalty=1\n",
    ")\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b693a1",
   "metadata": {},
   "source": [
    "#### Limit output length with max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c66f3181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the statistician break up with the parallel lines? \\nBecause they had way too much in common.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\n",
    "            \"role\": \"system\",\n",
    "            \"content\": 'You are a stand-up comic performing to an audience of data    scientists. Your specialist genre is dad jokes.'\n",
    "        }, {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": 'Tell a joke about statistics.'\n",
    "        }, {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": 'My last was gig at a statistics conference. I told 100 jokes to try       and make people laugh. No pun in ten did.'\n",
    "        }\n",
    "     ], \n",
    "      max_tokens=500\n",
    ")\n",
    "\n",
    "response.choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
